{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../../loaders/imports.py\n",
    "import sys, os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pdb\n",
    "\n",
    "# Add the uoicorr directory to the path\n",
    "sys.path.append('../../../uoicorr_run')\n",
    "\n",
    "# Add the root directory of this repository\n",
    "sys.path.append('../..')\n",
    "\n",
    "from postprocess_utils import *\n",
    "import pandas as pd\n",
    "import sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import gen_data, gen_covariance, sparsify_beta, gen_beta2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/media/akumar/Data/nse/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the non-concatenated dataframes to ensure indices are properly preserved\n",
    "lasso = pd.read_pickle('%s/finalfinal/lasso_df.dat' % root_dir)\n",
    "mcp = pd.read_pickle('%s/finalfinal/mcp_df.dat' % root_dir)\n",
    "scad = pd.read_pickle('%s/finalfinal/scad_df.dat' % root_dir)\n",
    "en = pd.read_pickle('%s/finalfinal/en_df.dat' % root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through each dataframe and isolate the sets of reps and calculate the bias and variance of estimates\n",
    "# 1) along the entire vector, 2) along the properly selected coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.239377777777777"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "460772 * 4/50/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning task!\n",
      "0.020168542861938477\n",
      "Beginning task!\n",
      "0.02080845832824707\n",
      "Beginning task!\n",
      "0.020191192626953125\n",
      "Beginning task!\n",
      "0.020018815994262695\n",
      "Beginning task!\n",
      "0.02045750617980957\n",
      "Beginning task!\n",
      "0.02052617073059082\n",
      "Beginning task!\n",
      "0.020495176315307617\n",
      "Beginning task!\n",
      "0.02040386199951172\n",
      "Beginning task!\n",
      "0.020600080490112305\n",
      "Beginning task!\n",
      "0.020561695098876953\n",
      "Beginning task!\n",
      "0.020243406295776367\n",
      "Beginning task!\n",
      "0.020472288131713867\n",
      "Beginning task!\n",
      "0.02054452896118164\n",
      "Beginning task!\n",
      "0.020373821258544922\n",
      "Beginning task!\n",
      "0.02042698860168457\n",
      "Beginning task!\n",
      "0.020612239837646484\n",
      "Beginning task!\n",
      "0.021223068237304688\n",
      "Beginning task!\n",
      "0.020627975463867188\n",
      "Beginning task!\n",
      "0.0208890438079834\n",
      "Beginning task!\n",
      "0.02079606056213379\n",
      "Beginning task!\n",
      "0.021254777908325195\n",
      "Beginning task!\n",
      "0.020152807235717773\n",
      "Beginning task!\n",
      "0.020513534545898438\n",
      "Beginning task!\n",
      "0.02063131332397461\n",
      "Beginning task!\n",
      "0.02083420753479004\n",
      "Beginning task!\n",
      "0.02037668228149414\n",
      "Beginning task!\n",
      "0.020412683486938477\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-9011f1beb57f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcidx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkappa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_combo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         df = apply_df_filters(dframe, sparsity=s, betawidth=bw, \n\u001b[0;32m---> 18\u001b[0;31m                                   selection_method=sm, cov_idx=cidx, kappa=kappa, np_ratio=npr)\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/nse/uoicorr_analysis/postprocess_utils.py\u001b[0m in \u001b[0;36mapply_df_filters\u001b[0;34m(df, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mfiltered_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiltered_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfiltered_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfiltered_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dframes = [lasso, mcp, scad, en]\n",
    "sparsity = np.unique(lasso['sparsity'].values)\n",
    "betawidth = np.unique(lasso['betawidth'].values)\n",
    "selection_methods = np.unique(lasso['selection_method'].values)\n",
    "kappa = np.unique(lasso['kappa'].values)\n",
    "np_ratio = np.unique(lasso['np_ratio'].values)\n",
    "cov_idxs = np.arange(80)\n",
    "\n",
    "beta_fnames = ['%s/finalfinal/%s_pp_beta.h5' % (root_dir, dfname) for dfname in ['lasso', 'mcp', 'scad', 'en']]\n",
    "beta_files = [h5py.File(beta_fname, 'r') for beta_fname in beta_fnames]\n",
    "\n",
    "param_combos = itertools.product(sparsity, betawidth, selection_methods, cov_idxs, kappa, np_ratio)\n",
    "\n",
    "for i, dframe in enumerate(dframes):\n",
    "    for param_combo in param_combos:\n",
    "        s, bw, sm, cidx, kappa, npr = param_combo\n",
    "        df = apply_df_filters(dframe, sparsity=s, betawidth=bw, \n",
    "                                  selection_method=sm, cov_idx=cidx, kappa=kappa, np_ratio=npr)\n",
    "        if df.shape[0] == 0:\n",
    "            continue\n",
    "        else:\n",
    "            print('Beginning task!')\n",
    "            try:\n",
    "                assert(df.shape[0] == 20)\n",
    "            except:\n",
    "                pdb.set_trace()\n",
    "            bias1, bias2, var = calc_bias_var(df, beta_files[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_bias_var(df, beta_file):\n",
    "    \n",
    "    indices = list(df.index)\n",
    "    \n",
    "    # Take the indices\n",
    "    beta = beta_file['beta'][indices, :]\n",
    "    # Ensure all the betas are the same\n",
    "    assert(np.isclose(beta, beta[0]).all())\n",
    "    \n",
    "    beta_hats = beta_file['beta_hat'][indices, :]\n",
    "    \n",
    "    # Total bias\n",
    "    total_bias = np.mean(np.linalg.norm(beta - beta_hats, axis=1))\n",
    "    \n",
    "    common_support_bias = 0\n",
    "    \n",
    "    # Common support bias\n",
    "    for i in range(len(indices)):\n",
    "        common_support = list(set(np.nonzero(beta[i, :])[0]).intersection(set(np.nonzero(beta_hats[i, :])[0])))\n",
    "        common_support_bias += 1/len(indices) * np.linalg.norm(beta[i, common_support] - beta_hats[i, common_support])\n",
    "    variance = np.mean(np.var(beta_hats, axis = 0))\n",
    "\n",
    "    return total_bias, common_support_bias, variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
