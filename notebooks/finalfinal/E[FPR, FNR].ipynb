{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../../loaders/imports.py\n",
    "import sys, os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pdb\n",
    "\n",
    "# Add the uoicorr directory to the path\n",
    "sys.path.append('../../../uoicorr_run')\n",
    "\n",
    "# Add the root directory of this repository\n",
    "sys.path.append('../..')\n",
    "\n",
    "from postprocess_utils import *\n",
    "import pandas as pd\n",
    "import sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from job_utils.idxpckl import Indexed_Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/media/akumar/Data/nse'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = pd.read_pickle('%s/finalfinal/lasso_concat_df.dat' % root_dir)\n",
    "mcp = pd.read_pickle('%s/finalfinal/mcp_concat_df.dat' % root_dir)\n",
    "scad = pd.read_pickle('%s/finalfinal/scad_concat_df.dat' % root_dir)\n",
    "en = pd.read_pickle('%s/finalfinal/en_concat_df.dat' % root_dir)\n",
    "uoi = pd.read_pickle('%s/finalfinal/uoi_concat_df.dat' % root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotting_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import gen_data, gen_covariance, sparsify_beta, gen_beta2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expand alpha datalist to encompass all SNR/N/P ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load precalculated ss and eigenvalue bounds\n",
    "with open('eigenvalue_ss.dat', 'rb') as f:\n",
    "    eigenvalue_bounds = pickle.load(f)\n",
    "    ss = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsity = np.unique(uoi['sparsity'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from expanded_ensemble import load_covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-sparsifty the beta for inverse exponential distribution and save away, as this is a time sink\n",
    "sparse_beta = []\n",
    "cov_idxs = np.arange(120)\n",
    "for k, s in enumerate(sparsity):            \n",
    "    for cov_idx in cov_idxs:\n",
    "        _, cov_param = load_covariance(cov_idx)\n",
    "        # take the minimum non-zero beta value\n",
    "        beta = gen_beta2(500, 500, \n",
    "                         1, -1, seed=1234, distribution='normal')        \n",
    "        # Sparsify beta\n",
    "        beta = sparsify_beta(beta, cov_param['block_size'], s,\n",
    "                             seed = cov_param['block_size'])\n",
    "        sparse_beta.append({'sparsity': s, 'cov_idx': cov_idx, 'beta': beta})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_params = [] \n",
    "for cov_idx in np.arange(120):\n",
    "    _, cp = load_covariance(cov_idx)\n",
    "    cov_params.append(cp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_beta = pd.DataFrame(sparse_beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eigenvalue constant\n",
    "def calc_alpha_sa(cov_indices, df, rho, ss_, flag, threshold=1):\n",
    "    t0 = time.time()\n",
    "    alphas = np.zeros(len(cov_indices))    \n",
    "    sa = np.zeros((len(cov_indices)))\n",
    "    for i, cov_idx in enumerate(cov_indices):\n",
    "        df_ = apply_df_filters(df, cov_idx=cov_idx)        \n",
    "        cov_param = cov_params[cov_idx]\n",
    "\n",
    "        # Use pregenerated beta for inverse exp due to slow time for rejection sampling\n",
    "        if df_.iloc[0]['betawidth'] == -1:\n",
    "            sb = apply_df_filters(sparse_beta, cov_idx=cov_idx, sparsity=df.iloc[0]['sparsity'])\n",
    "            beta = sb.iloc[0]['beta']\n",
    "        else:\n",
    "            # take the minimum non-zero beta value\n",
    "            beta = gen_beta2(df_.iloc[0]['n_features'], df_.iloc[0]['n_features'], 1, df_.iloc[0]['betawidth'], seed=1234, distribution='normal')                \n",
    "            # Sparsify beta\n",
    "            beta = sparsify_beta(beta[np.newaxis, :], cov_param['block_size'], df_.iloc[0]['sparsity'], seed = cov_param['block_size'])\n",
    "\n",
    "        beta=beta.ravel()\n",
    "\n",
    "        alphas[i] = np.mean(rho[i] * np.min(np.abs(beta[np.nonzero(beta)[0]]))/ss_[i])\n",
    "\n",
    "        # Just return the average selection accuracy\n",
    "        if flag is None:\n",
    "            sa[i] = np.mean(df_['sa'].values)\n",
    "\n",
    "        if flag == 'threshold':\n",
    "            sa[i] = np.count_nonzero(1 * df_.iloc[cov_indices[i]]['sa'].values > threshold)/len(cov_indices[i])\n",
    "           \n",
    "    return alphas, sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
       "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_datalist_u\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe: UoI Lasso, bw_idx: 0, time: 811.305557\n",
      "Dataframe: UoI Lasso, bw_idx: 1, time: 758.539385\n",
      "Dataframe: UoI Lasso, bw_idx: 2, time: 757.437975\n",
      "Dataframe: Lasso, bw_idx: 0, time: 1148.994747\n",
      "Dataframe: Lasso, bw_idx: 1, time: 1048.645408\n",
      "Dataframe: Lasso, bw_idx: 2, time: 1047.702638\n",
      "Dataframe: MCP, bw_idx: 0, time: 1114.218609\n",
      "Dataframe: MCP, bw_idx: 1, time: 1023.190513\n",
      "Dataframe: MCP, bw_idx: 2, time: 1018.283912\n",
      "Dataframe: SCAD, bw_idx: 0, time: 1089.721250\n",
      "Dataframe: SCAD, bw_idx: 1, time: 1021.049241\n",
      "Dataframe: SCAD, bw_idx: 2, time: 1017.992569\n",
      "Dataframe: EN, bw_idx: 0, time: 1093.112985\n",
      "Dataframe: EN, bw_idx: 1, time: 1025.993290\n",
      "Dataframe: EN, bw_idx: 2, time: 1021.290996\n"
     ]
    }
   ],
   "source": [
    "# Plot either the average selection accuracy or the percent of runs that exceed a certain threshold as a \n",
    "# function of the parameter alpha. alpha = rho(Omega) sum(beta_min^2)/sigma^2\n",
    "\n",
    "# Calculate across signal to noise ratios, n/p ratio = 4\n",
    "kappa = np.unique(lasso['kappa'].values)\n",
    "np_ratios = np.unique(lasso['np_ratio'].values)\n",
    "betawidth = np.unique(lasso['betawidth'].values)\n",
    "selection_methods = np.unique(lasso['selection_method'])\n",
    "dframes = [uoi, lasso, mcp, scad, en]\n",
    "#dframes = [uoi, en]\n",
    "dframe_names = ['UoI Lasso', 'Lasso', 'MCP', 'SCAD', 'EN']\n",
    "# Need to create a dataframe \n",
    "alpha_datalist_uoi = []\n",
    "\n",
    "for i, dframe in enumerate(dframes):                \n",
    "    for j, bw in enumerate(betawidth):\n",
    "        t0 = time.time()\n",
    "        for h, sm in enumerate(selection_methods):\n",
    "            for k, s in enumerate(sparsity):            \n",
    "                for ii, kappa_ in enumerate(kappa):\n",
    "                    for jj, np_ratio_ in enumerate(np_ratios):\n",
    "                        df = apply_df_filters(dframe, kappa=kappa_, np_ratio=np_ratio_, selection_method=sm,\n",
    "                                              betawidth=bw, sparsity=s)\n",
    "                        cov_indices = np.unique(df['cov_idx'].values) \n",
    "                        alpha_, sa_ = calc_alpha_sa(cov_indices, df, rho=eigenvalue_bounds[:, k],\n",
    "                                                    ss_=ss[:, k, j], flag=None) \n",
    "                        alpha_datalist_uoi.append({'df_name' : dframe_names[i], 'betawidth': bw, 'sparsity' : s,\n",
    "                                               'alpha': alpha_, 'sa': sa_, 'kappa' : kappa_, \n",
    "                                               'selection_method': sm, 'np_ratio': np_ratio_,\n",
    "                                               'cov_indices': cov_indices})       \n",
    "        print('Dataframe: %s, bw_idx: %d, time: %f' % (dframe_names[i], j, time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save \n",
    "import pickle\n",
    "with open('alpha_datalist_expanded.dat', 'wb') as f:\n",
    "    f.write(pickle.dumps(alpha_datalist_uoi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_datalist = pd.DataFrame(alpha_datalist_uoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "uoi_ = apply_df_filters(uoi, betawidth=-1, sparsity=alpha_datalist.iloc[0]['sparsity'], kappa=1, selection_method='AIC',\n",
    "                        np_ratio=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df_name                                                     UoI Lasso\n",
       "betawidth                                                          -1\n",
       "sparsity                                                         0.02\n",
       "alpha               [0.00037392887190799127, 0.00793968761035703, ...\n",
       "sa                  [0.10931532289733101, 0.17024821340990917, 0.1...\n",
       "kappa                                                               1\n",
       "selection_method                                                  AIC\n",
       "np_ratio                                                            2\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_datalist.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adopt the following scheme to simplify the metric presented:\n",
    "\n",
    "# Across model densities:\n",
    "# (1) Divide into 3 equal correlation strengths (alpha)\n",
    "# (2) Divide into \"high noise\", \"low data\", \"high noise, low data\", \"ideal\" conditions\n",
    "# (3) Keep betawidth together\n",
    "# (4) Calculate E(FNR), E(FPR) and variance for each combination of selection method/algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  4,  8, 16])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dframes = [uoi, lasso, mcp, en, scad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_(case_alpha_df, case_params):\n",
    "    \n",
    "    results_list =[]    \n",
    "    \n",
    "    # Narrow down dframes to case params\n",
    "    case_dframes = [apply_df_filters(df, **case_params) for df in dframes]\n",
    "    \n",
    "    dframe_names = ['UoI Lasso', 'Lasso', 'MCP', 'EN', 'SCAD']\n",
    "    selection_methods = ['AIC', 'BIC', 'CV', 'gMDL', 'empirical_bayes', 'oracle']\n",
    "    \n",
    "    for i, dframe in enumerate(case_dframes):\n",
    "        for sm in selection_methods:\n",
    "            # At this stage, only betawidths should be residual\n",
    "            cadf = apply_df_filters(case_alpha_df, df_name=dframe_names[i], selection_method=sm)\n",
    "            df_ = apply_df_filters(dframe, selection_method=sm)\n",
    "            \n",
    "            try:\n",
    "                assert(cadf.shape[0] == 3)\n",
    "            except:\n",
    "                pdb.set_trace()\n",
    "            alpha_sizes = [cadf.iloc[ii]['alpha'].size for ii in range(3)]\n",
    "            assert(alpha_sizes[0] == alpha_sizes[1] and alpha_sizes[1] == alpha_sizes[2])\n",
    "            \n",
    "            # If so, just grab the alphas from the first betawidth in the \n",
    "            alphas = case_alpha_df.iloc[0]['alpha'].ravel()\n",
    "            \n",
    "            try:\n",
    "                # Make sure that the number of unique cov_idxs match the number of alphas\n",
    "                assert(np.unique(df_['cov_idx'].values).size == alphas.size)\n",
    "            except:\n",
    "                pdb.set_trace()\n",
    "            # mask the alpha indices\n",
    "            alpha_mask = np.ma.log(alphas)\n",
    "            mask = np.invert(alpha_mask.mask)\n",
    "            \n",
    "            alpha_ordering= np.argsort(np.log(alphas[mask]))\n",
    "            \n",
    "            # group cov_idxs appropriately into 3 groups\n",
    "            cov_idx_groups = np.array_split(np.arange(alphas.size)[mask][alpha_ordering], 3)\n",
    "\n",
    "            for k, cig in enumerate(cov_idx_groups):\n",
    "                \n",
    "                df_cig = df_.loc[df_['cov_idx'].isin(cig)]\n",
    "                # Take the mean and variance of the FPR and FNR\n",
    "                EFPR = np.mean(df_cig['FPR'].values)\n",
    "                EFNR = np.mean(df_cig['FNR'].values)\n",
    "                stdFPR = np.std(df_cig['FPR'].values)\n",
    "                stdFNR = np.std(df_cig['FNR'].values)\n",
    "\n",
    "                \n",
    "                # Append the \n",
    "                results = {'df_name': dframe_names[i], 'selection_method': sm,\n",
    "                           'EFPR': EFPR, 'EFNR': EFNR, 'stdFPR': stdFPR, 'stdFNR': stdFNR,\n",
    "                           'cidx_group': k, 'cov_indices': cig}\n",
    "                results.update(case_params)\n",
    "                \n",
    "                results_list.append(results)\n",
    "    return results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-87-8e02f7137db7>(33)calc_()\n",
      "-> alpha_mask = np.ma.log(alphas)\n",
      "(Pdb) cadf.shape\n",
      "(3, 8)\n",
      "(Pdb) np.unique(df_['cov_idx'].values).size\n",
      "80\n",
      "(Pdb) alphas.size\n",
      "79\n",
      "(Pdb) df_['cov_idx'].values\n",
      "array([54, 54, 54, ..., 57, 57, 57])\n",
      "(Pdb) np.unique(df_['cov_idx'].values)\n",
      "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
      "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
      "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
      "       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79])\n",
      "--KeyboardInterrupt--\n",
      "(Pdb) quit()\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-507be1411c97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mcase1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_df_filters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkappa\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0me_fpr_fnr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalc_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcase1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'kappa'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'np_ratio'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sparsity'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Normal noise, low data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-87-8e02f7137db7>\u001b[0m in \u001b[0;36mcalc_\u001b[0;34m(case_alpha_df, case_params)\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;31m# mask the alpha indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0malpha_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malphas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-87-8e02f7137db7>\u001b[0m in \u001b[0;36mcalc_\u001b[0;34m(case_alpha_df, case_params)\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;31m# mask the alpha indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0malpha_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malphas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nse/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nse/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "e_fpr_fnr = []\n",
    "for i, s in enumerate(sparsity):\n",
    "    \n",
    "    adl = apply_df_filters(alpha_datalist, sparsity=s)\n",
    "    \n",
    "    # High noise, normal n/p ratio\n",
    "    case1 = apply_df_filters(adl, kappa=1, np_ratio=4)\n",
    "\n",
    "    e_fpr_fnr.append(calc_(case1, {'kappa' : 1, 'np_ratio': 4, 'sparsity': s}))\n",
    "    \n",
    "    # Normal noise, low data\n",
    "    case2 = apply_df_filters(adl, kappa=5, np_ratio=2)\n",
    "    \n",
    "    e_fpr_fnr.append(calc_(case2, {'kappa' : 5, 'np_ratio': 2, 'sparsity': s}))\n",
    "                     \n",
    "    # ideal\n",
    "    case3 = apply_df_filters(adl, kappa=10, np_ratio=16)\n",
    "    \n",
    "    e_fpr_fnr.append(calc_(case3, {'kappa' : 10, 'np_ratio': 16, 'sparsity': s}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(e_fpr_fnr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(e_fpr_fnr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "765"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "45 * 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-86-4250ac754c83>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-86-4250ac754c83>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    45 ( 18})\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "45 ( 18})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
